{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e5eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: detecto in d:\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: torch in d:\\anaconda3\\lib\\site-packages (from detecto) (1.11.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (from detecto) (1.4.2)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda3\\lib\\site-packages (from detecto) (3.5.1)\n",
      "Requirement already satisfied: opencv-python in d:\\anaconda3\\lib\\site-packages (from detecto) (4.5.5.64)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from detecto) (4.64.0)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda3\\lib\\site-packages (from detecto) (0.12.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib->detecto) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib->detecto) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda3\\lib\\site-packages (from matplotlib->detecto) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib->detecto) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib->detecto) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib->detecto) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda3\\lib\\site-packages (from matplotlib->detecto) (1.21.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib->detecto) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->detecto) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\lib\\site-packages (from pandas->detecto) (2021.3)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\lib\\site-packages (from torch->detecto) (4.1.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (from torchvision->detecto) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests->torchvision->detecto) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests->torchvision->detecto) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda3\\lib\\site-packages (from requests->torchvision->detecto) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests->torchvision->detecto) (3.3)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm->detecto) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install detecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11535606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detecto import core, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e41ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c601e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87bf81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>Print OK</td>\n",
       "      <td>373</td>\n",
       "      <td>681</td>\n",
       "      <td>3888</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>LH</td>\n",
       "      <td>281</td>\n",
       "      <td>563</td>\n",
       "      <td>1375</td>\n",
       "      <td>1355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>SP</td>\n",
       "      <td>412</td>\n",
       "      <td>779</td>\n",
       "      <td>1132</td>\n",
       "      <td>1198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>Print OK</td>\n",
       "      <td>445</td>\n",
       "      <td>694</td>\n",
       "      <td>3823</td>\n",
       "      <td>2121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>LH</td>\n",
       "      <td>517</td>\n",
       "      <td>733</td>\n",
       "      <td>1447</td>\n",
       "      <td>1237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>98.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>RH</td>\n",
       "      <td>2801</td>\n",
       "      <td>1080</td>\n",
       "      <td>3567</td>\n",
       "      <td>1689</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>98.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>SP</td>\n",
       "      <td>2854</td>\n",
       "      <td>1145</td>\n",
       "      <td>3449</td>\n",
       "      <td>1551</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>99.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>Print OK</td>\n",
       "      <td>79</td>\n",
       "      <td>982</td>\n",
       "      <td>3561</td>\n",
       "      <td>2062</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>99.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>RH</td>\n",
       "      <td>2684</td>\n",
       "      <td>1041</td>\n",
       "      <td>3567</td>\n",
       "      <td>1774</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>99.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>SP</td>\n",
       "      <td>2769</td>\n",
       "      <td>1126</td>\n",
       "      <td>3443</td>\n",
       "      <td>1577</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename  width  height     class  xmin  ymin  xmax  ymax  image_id\n",
       "0      1.jpg   4032    3024  Print OK   373   681  3888  2003         0\n",
       "1      1.jpg   4032    3024        LH   281   563  1375  1355         0\n",
       "2      1.jpg   4032    3024        SP   412   779  1132  1198         0\n",
       "3     10.jpg   4032    3024  Print OK   445   694  3823  2121         1\n",
       "4     10.jpg   4032    3024        LH   517   733  1447  1237         1\n",
       "..       ...    ...     ...       ...   ...   ...   ...   ...       ...\n",
       "430   98.jpg   4032    3024        RH  2801  1080  3567  1689       143\n",
       "431   98.jpg   4032    3024        SP  2854  1145  3449  1551       143\n",
       "432   99.jpg   4032    3024  Print OK    79   982  3561  2062       144\n",
       "433   99.jpg   4032    3024        RH  2684  1041  3567  1774       144\n",
       "434   99.jpg   4032    3024        SP  2769  1126  3443  1577       144\n",
       "\n",
       "[435 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.xml_to_csv(r\"C:\\Users\\asannidhi\\Downloads\\labels_my-project-name_2022-06-24-09-28-24\", 'train_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e0ca4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>Print OK</td>\n",
       "      <td>137</td>\n",
       "      <td>511</td>\n",
       "      <td>3862</td>\n",
       "      <td>1610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>LH</td>\n",
       "      <td>131</td>\n",
       "      <td>707</td>\n",
       "      <td>1028</td>\n",
       "      <td>1460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>SP</td>\n",
       "      <td>183</td>\n",
       "      <td>779</td>\n",
       "      <td>877</td>\n",
       "      <td>1381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>Print OK</td>\n",
       "      <td>203</td>\n",
       "      <td>563</td>\n",
       "      <td>3908</td>\n",
       "      <td>1577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>LH</td>\n",
       "      <td>255</td>\n",
       "      <td>622</td>\n",
       "      <td>1106</td>\n",
       "      <td>1453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>8.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>LH</td>\n",
       "      <td>157</td>\n",
       "      <td>622</td>\n",
       "      <td>1113</td>\n",
       "      <td>1453</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>8.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>SP</td>\n",
       "      <td>223</td>\n",
       "      <td>733</td>\n",
       "      <td>857</td>\n",
       "      <td>1355</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>9.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>Print OK</td>\n",
       "      <td>157</td>\n",
       "      <td>550</td>\n",
       "      <td>3927</td>\n",
       "      <td>1604</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>9.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>LH</td>\n",
       "      <td>196</td>\n",
       "      <td>615</td>\n",
       "      <td>1100</td>\n",
       "      <td>1532</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>9.jpg</td>\n",
       "      <td>4032</td>\n",
       "      <td>3024</td>\n",
       "      <td>SP</td>\n",
       "      <td>242</td>\n",
       "      <td>753</td>\n",
       "      <td>943</td>\n",
       "      <td>1361</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename  width  height     class  xmin  ymin  xmax  ymax  image_id\n",
       "0      1.jpg   4032    3024  Print OK   137   511  3862  1610         0\n",
       "1      1.jpg   4032    3024        LH   131   707  1028  1460         0\n",
       "2      1.jpg   4032    3024        SP   183   779   877  1381         0\n",
       "3     10.jpg   4032    3024  Print OK   203   563  3908  1577         1\n",
       "4     10.jpg   4032    3024        LH   255   622  1106  1453         1\n",
       "..       ...    ...     ...       ...   ...   ...   ...   ...       ...\n",
       "124    8.jpg   4032    3024        LH   157   622  1113  1453        41\n",
       "125    8.jpg   4032    3024        SP   223   733   857  1355        41\n",
       "126    9.jpg   4032    3024  Print OK   157   550  3927  1604        42\n",
       "127    9.jpg   4032    3024        LH   196   615  1100  1532        42\n",
       "128    9.jpg   4032    3024        SP   242   753   943  1361        42\n",
       "\n",
       "[129 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.xml_to_csv(r\"C:\\Users\\asannidhi\\Downloads\\labels_my-project-name_2022-06-24-10-49-58\", 'val_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14695623",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(800),\n",
    "    transforms.ColorJitter(saturation=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    utils.normalize_transform(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "534d7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = core.Dataset('train_labels.csv', r\"C:\\Users\\asannidhi\\Desktop\\train_data\\images\\train\", transform=custom_transforms)\n",
    "val_dataset = core.Dataset('val_labels.csv', r\"C:\\Users\\asannidhi\\Desktop\\train_data\\images\\val\")  # Validation dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371bee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own DataLoader with custom options\n",
    "loader = core.DataLoader(dataset, batch_size=6, shuffle=True) \n",
    "# Use MobileNet instead of the default ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9504eea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you're training your model on a CPU. Consider switching to a GPU; otherwise, this method can take hours upon hours or even days to finish. For more information, see https://detecto.readthedocs.io/en/latest/usage/quickstart.html#technical-requirements\n",
      "Epoch 1 of 10\n",
      "Begin iterating over training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [07:19<00:00, 17.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin iterating over validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [01:16<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0947882089503975\n",
      "Epoch 2 of 10\n",
      "Begin iterating over training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [07:27<00:00, 17.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin iterating over validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [01:18<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9105008882145549\n",
      "Epoch 3 of 10\n",
      "Begin iterating over training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [07:44<00:00, 18.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin iterating over validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [01:22<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8442843847496565\n",
      "Epoch 4 of 10\n",
      "Begin iterating over training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [07:37<00:00, 18.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin iterating over validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [01:28<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8023831359175748\n",
      "Epoch 5 of 10\n",
      "Begin iterating over training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [09:05<00:00, 21.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin iterating over validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [01:30<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.789836724137151\n",
      "Epoch 6 of 10\n",
      "Begin iterating over training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [07:47<00:00, 18.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin iterating over validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▊                                                         | 13/43 [00:28<01:04,  2.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mModel([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLH\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRH\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSP\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrint OK\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmudge\u001b[39m\u001b[38;5;124m'\u001b[39m], model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfasterrcnn_mobilenet_v3_large_fpn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\detecto\\core.py:544\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, dataset, val_dataset, epochs, learning_rate, momentum, weight_decay, gamma, lr_step_size, verbose)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_int_labels(targets)\n\u001b[0;32m    543\u001b[0m images, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_device(images, targets)\n\u001b[1;32m--> 544\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    546\u001b[0m avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:99\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     97\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n\u001b[0;32m     98\u001b[0m proposals, proposal_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrpn(images, features, targets)\n\u001b[1;32m---> 99\u001b[0m detections, detector_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mpostprocess(detections, images\u001b[38;5;241m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m    102\u001b[0m losses \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py:751\u001b[0m, in \u001b[0;36mRoIHeads.forward\u001b[1;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[0;32m    748\u001b[0m     regression_targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    749\u001b[0m     matched_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 751\u001b[0m box_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbox_roi_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m box_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_head(box_features)\n\u001b[0;32m    753\u001b[0m class_logits, box_regression \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_predictor(box_features)\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torchvision\\ops\\poolers.py:331\u001b[0m, in \u001b[0;36mMultiScaleRoIAlign.forward\u001b[1;34m(self, x, boxes, image_shapes)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscales \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_levels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscales, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_levels \u001b[38;5;241m=\u001b[39m _setup_scales(\n\u001b[0;32m    328\u001b[0m         x_filtered, image_shapes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanonical_scale, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanonical_level\n\u001b[0;32m    329\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiscale_roi_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_filtered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torchvision\\ops\\poolers.py:205\u001b[0m, in \u001b[0;36m_multiscale_roi_align\u001b[1;34m(x_filtered, boxes, output_size, sampling_ratio, scales, mapper)\u001b[0m\n\u001b[0;32m    202\u001b[0m idx_in_level \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(levels \u001b[38;5;241m==\u001b[39m level)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    203\u001b[0m rois_per_level \u001b[38;5;241m=\u001b[39m rois[idx_in_level]\n\u001b[1;32m--> 205\u001b[0m result_idx_in_level \u001b[38;5;241m=\u001b[39m \u001b[43mroi_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_level_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrois_per_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torchvision\u001b[38;5;241m.\u001b[39m_is_tracing():\n\u001b[0;32m    214\u001b[0m     tracing_results\u001b[38;5;241m.\u001b[39mappend(result_idx_in_level\u001b[38;5;241m.\u001b[39mto(dtype))\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torchvision\\ops\\roi_align.py:61\u001b[0m, in \u001b[0;36mroi_align\u001b[1;34m(input, boxes, output_size, spatial_scale, sampling_ratio, aligned)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rois, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     60\u001b[0m     rois \u001b[38;5;241m=\u001b[39m convert_boxes_to_roi_format(rois)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = core.Model(['LH','RH','SP','Print OK','Smudge'], model_name='fasterrcnn_mobilenet_v3_large_fpn')\n",
    "losses = model.fit(loader, val_dataset, epochs=10, learning_rate=0.001, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58400ef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mlosses\u001b[49m)  \u001b[38;5;66;03m# Visualize loss throughout training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow()\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Save model to a file\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)  # Visualize loss throughout training\n",
    "plt.imshow()\n",
    "\n",
    "model.save('model_weights.pth')  # Save model to a file\n",
    "\n",
    "# Directly access underlying torchvision model for even more control\n",
    "torch_model = model.get_internal_model()\n",
    "print(type(torch_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf93ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
